{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67d98YQ9Em9J"
   },
   "source": [
    "# üìú Projeto Final - Capacita√ß√£o IA (Ciclo 3)\n",
    "# üéì Alunos: Filipe da Silva Rodrigues e Rodrigo Serafim Floriano da Silva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0T3nUxV-Em9L"
   },
   "source": [
    "## üíª Bibliotecas Necess√°rias"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T16:41:15.402060Z",
     "start_time": "2024-11-15T16:41:15.396734Z"
    }
   },
   "source": [
    "# Instala√ß√£o de bibliotecas necess√°rias para execu√ß√£o do c√≥digo\n",
    "# !pip install numpy pandas scikit-learn mlflow xgboost lightgbm catboost tpot pytorch --quiet"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Xx3sAPU_Em9L",
    "ExecuteTime": {
     "end_time": "2024-11-15T16:41:21.343899Z",
     "start_time": "2024-11-15T16:41:15.434070Z"
    }
   },
   "source": [
    "# Tratamento de Dataset e M√©tricas\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Modelos de Treinamento\n",
    "\n",
    "# Classificadores b√°sicos\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Classificadores avan√ßados\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# AutoML\n",
    "from tpot import TPOTClassifier\n",
    "\n",
    "# Armazenamento e An√°lise de Modelos\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.pyfunc\n",
    "from mlflow import pyfunc\n",
    "\n",
    "# Terminal\n",
    "\n",
    "import warnings\n",
    "from IPython.display import clear_output\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rieolC1PEm9M"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "üëæ **Dataset de Classifica√ß√£o - Kaggle: Water Quality**\n",
    "\n",
    "Esse dataframe √© um conjunto de dados que cont√©m informa√ß√µes sobre a qualidade da √°gua e sua potabilidade. As vari√°veis s√£o:\n",
    "\n",
    "- `ph`: o valor do pH da √°gua (0 a 14).\n",
    "- `Hardness`: a capacidade da √°gua de precipitar sab√£o em mg/L.\n",
    "- `Solids`: s√≥lidos totais dissolvidos em ppm.\n",
    "- `Chloramines`: quantidade de cloraminas em ppm.\n",
    "- `Sulfate`: quantidade de sulfatos dissolvidos em mg/L.\n",
    "- `Conductivity`: condutividade el√©trica da √°gua em ŒºS/cm.\n",
    "- `Organic_carbon`: quantidade de carbono org√¢nico em ppm.\n",
    "- `Trihalomethanes`: quantidade de trihalometanos em Œºg/L.\n",
    "- `Turbidity`: medida da propriedade de emiss√£o de luz da √°gua em NTU.\n",
    "- `Potability`: indica se a √°gua √© segura para consumo humano (1 = Pot√°vel, 0 = N√£o pot√°vel).\n",
    "\n",
    "‚úÖ **Objetivo:** Prever se a √°gua √© pot√°vel ou n√£o com base nas caracter√≠sticas coletadas.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o_F2jeyjEm9M",
    "outputId": "50e652ed-7ad9-49ca-eac7-c8c045500bb3",
    "ExecuteTime": {
     "end_time": "2024-11-15T16:41:21.476922Z",
     "start_time": "2024-11-15T16:41:21.420921Z"
    }
   },
   "source": [
    "# Carregar o dataset\n",
    "url = 'water_potability.csv'\n",
    "dataset = pd.read_csv(url)\n",
    "\n",
    "# Analisar o dataset\n",
    "print('\\nInforma√ß√µes do Dataset:\\n')\n",
    "display(dataset.info())\n",
    "\n",
    "print('\\nVerificar Valores Nulos:\\n')\n",
    "display(dataset.isnull().sum())\n",
    "\n",
    "# Exibir o dataset original\n",
    "print('\\nDataset Original:\\n')\n",
    "display(dataset)\n",
    "\n",
    "# Remover os registros com valores nulos\n",
    "dataset = dataset.dropna()\n",
    "\n",
    "# Criar uma c√≥pia do dataset para efetuar os devidos tratamentos\n",
    "df = dataset.copy()\n",
    "\n",
    "# Normalizando os dados das features na escala (0..1)\n",
    "columns_to_normalize = ['ph', 'Hardness', 'Solids', 'Chloramines', 'Sulfate', 'Conductivity', 'Organic_carbon', 'Trihalomethanes', 'Turbidity']\n",
    "df[columns_to_normalize] = MinMaxScaler().fit_transform(df[columns_to_normalize])\n",
    "\n",
    "# Separar os dados para o tratamento de features\n",
    "target = df['Potability'].copy()\n",
    "features = df.drop('Potability', axis=1).copy()\n",
    "\n",
    "# Combinando as features transformadas com o target\n",
    "df = pd.concat(\n",
    "    [features.reset_index(drop=True), target.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Exibindo o DataFrame tratado com as colunas renomeadas\n",
    "print('\\nDataset Tratado para Treinamento:\\n')\n",
    "display(df)\n",
    "\n",
    "\n",
    "# Separando os dados \n",
    "y = df['Potability']  # Coluna 'Potability'\n",
    "x = df.drop('Potability', axis=1)  # Todas as outras colunas\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=None)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Informa√ß√µes do Dataset:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3276 entries, 0 to 3275\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   ph               2785 non-null   float64\n",
      " 1   Hardness         3276 non-null   float64\n",
      " 2   Solids           3276 non-null   float64\n",
      " 3   Chloramines      3276 non-null   float64\n",
      " 4   Sulfate          2495 non-null   float64\n",
      " 5   Conductivity     3276 non-null   float64\n",
      " 6   Organic_carbon   3276 non-null   float64\n",
      " 7   Trihalomethanes  3114 non-null   float64\n",
      " 8   Turbidity        3276 non-null   float64\n",
      " 9   Potability       3276 non-null   int64  \n",
      "dtypes: float64(9), int64(1)\n",
      "memory usage: 256.1 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Verificar Valores Nulos:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ph                 491\n",
       "Hardness             0\n",
       "Solids               0\n",
       "Chloramines          0\n",
       "Sulfate            781\n",
       "Conductivity         0\n",
       "Organic_carbon       0\n",
       "Trihalomethanes    162\n",
       "Turbidity            0\n",
       "Potability           0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Original:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "            ph    Hardness        Solids  Chloramines     Sulfate  \\\n",
       "0          NaN  204.890455  20791.318981     7.300212  368.516441   \n",
       "1     3.716080  129.422921  18630.057858     6.635246         NaN   \n",
       "2     8.099124  224.236259  19909.541732     9.275884         NaN   \n",
       "3     8.316766  214.373394  22018.417441     8.059332  356.886136   \n",
       "4     9.092223  181.101509  17978.986339     6.546600  310.135738   \n",
       "...        ...         ...           ...          ...         ...   \n",
       "3271  4.668102  193.681735  47580.991603     7.166639  359.948574   \n",
       "3272  7.808856  193.553212  17329.802160     8.061362         NaN   \n",
       "3273  9.419510  175.762646  33155.578218     7.350233         NaN   \n",
       "3274  5.126763  230.603758  11983.869376     6.303357         NaN   \n",
       "3275  7.874671  195.102299  17404.177061     7.509306         NaN   \n",
       "\n",
       "      Conductivity  Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
       "0       564.308654       10.379783        86.990970   2.963135           0  \n",
       "1       592.885359       15.180013        56.329076   4.500656           0  \n",
       "2       418.606213       16.868637        66.420093   3.055934           0  \n",
       "3       363.266516       18.436524       100.341674   4.628771           0  \n",
       "4       398.410813       11.558279        31.997993   4.075075           0  \n",
       "...            ...             ...              ...        ...         ...  \n",
       "3271    526.424171       13.894419        66.687695   4.435821           1  \n",
       "3272    392.449580       19.903225              NaN   2.798243           1  \n",
       "3273    432.044783       11.039070        69.845400   3.298875           1  \n",
       "3274    402.883113       11.168946        77.488213   4.708658           1  \n",
       "3275    327.459760       16.140368        78.698446   2.309149           1  \n",
       "\n",
       "[3276 rows x 10 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Solids</th>\n",
       "      <th>Chloramines</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Organic_carbon</th>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>204.890455</td>\n",
       "      <td>20791.318981</td>\n",
       "      <td>7.300212</td>\n",
       "      <td>368.516441</td>\n",
       "      <td>564.308654</td>\n",
       "      <td>10.379783</td>\n",
       "      <td>86.990970</td>\n",
       "      <td>2.963135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.716080</td>\n",
       "      <td>129.422921</td>\n",
       "      <td>18630.057858</td>\n",
       "      <td>6.635246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>592.885359</td>\n",
       "      <td>15.180013</td>\n",
       "      <td>56.329076</td>\n",
       "      <td>4.500656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.099124</td>\n",
       "      <td>224.236259</td>\n",
       "      <td>19909.541732</td>\n",
       "      <td>9.275884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>418.606213</td>\n",
       "      <td>16.868637</td>\n",
       "      <td>66.420093</td>\n",
       "      <td>3.055934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.316766</td>\n",
       "      <td>214.373394</td>\n",
       "      <td>22018.417441</td>\n",
       "      <td>8.059332</td>\n",
       "      <td>356.886136</td>\n",
       "      <td>363.266516</td>\n",
       "      <td>18.436524</td>\n",
       "      <td>100.341674</td>\n",
       "      <td>4.628771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.092223</td>\n",
       "      <td>181.101509</td>\n",
       "      <td>17978.986339</td>\n",
       "      <td>6.546600</td>\n",
       "      <td>310.135738</td>\n",
       "      <td>398.410813</td>\n",
       "      <td>11.558279</td>\n",
       "      <td>31.997993</td>\n",
       "      <td>4.075075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3271</th>\n",
       "      <td>4.668102</td>\n",
       "      <td>193.681735</td>\n",
       "      <td>47580.991603</td>\n",
       "      <td>7.166639</td>\n",
       "      <td>359.948574</td>\n",
       "      <td>526.424171</td>\n",
       "      <td>13.894419</td>\n",
       "      <td>66.687695</td>\n",
       "      <td>4.435821</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3272</th>\n",
       "      <td>7.808856</td>\n",
       "      <td>193.553212</td>\n",
       "      <td>17329.802160</td>\n",
       "      <td>8.061362</td>\n",
       "      <td>NaN</td>\n",
       "      <td>392.449580</td>\n",
       "      <td>19.903225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.798243</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3273</th>\n",
       "      <td>9.419510</td>\n",
       "      <td>175.762646</td>\n",
       "      <td>33155.578218</td>\n",
       "      <td>7.350233</td>\n",
       "      <td>NaN</td>\n",
       "      <td>432.044783</td>\n",
       "      <td>11.039070</td>\n",
       "      <td>69.845400</td>\n",
       "      <td>3.298875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3274</th>\n",
       "      <td>5.126763</td>\n",
       "      <td>230.603758</td>\n",
       "      <td>11983.869376</td>\n",
       "      <td>6.303357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>402.883113</td>\n",
       "      <td>11.168946</td>\n",
       "      <td>77.488213</td>\n",
       "      <td>4.708658</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3275</th>\n",
       "      <td>7.874671</td>\n",
       "      <td>195.102299</td>\n",
       "      <td>17404.177061</td>\n",
       "      <td>7.509306</td>\n",
       "      <td>NaN</td>\n",
       "      <td>327.459760</td>\n",
       "      <td>16.140368</td>\n",
       "      <td>78.698446</td>\n",
       "      <td>2.309149</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3276 rows √ó 10 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Tratado para Treinamento:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "            ph  Hardness    Solids  Chloramines   Sulfate  Conductivity  \\\n",
       "0     0.587349  0.577747  0.386298     0.568199  0.647347      0.292985   \n",
       "1     0.643654  0.441300  0.314381     0.439304  0.514545      0.356685   \n",
       "2     0.388934  0.470876  0.506122     0.524364  0.561537      0.142913   \n",
       "3     0.725820  0.715942  0.506141     0.521683  0.751819      0.148683   \n",
       "4     0.610517  0.532588  0.237701     0.270288  0.495155      0.494792   \n",
       "...        ...       ...       ...          ...       ...           ...   \n",
       "2006  0.636224  0.580511  0.277748     0.418063  0.522486      0.342184   \n",
       "2007  0.470143  0.548826  0.301347     0.538273  0.498565      0.231359   \n",
       "2008  0.817826  0.087434  0.656389     0.670774  0.369089      0.431872   \n",
       "2009  0.424187  0.464092  0.459656     0.541633  0.615572      0.388360   \n",
       "2010  0.322425  0.492891  0.841409     0.492136  0.656047      0.588709   \n",
       "\n",
       "      Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
       "0           0.654522         0.795029   0.630115           0  \n",
       "1           0.377248         0.202914   0.520358           0  \n",
       "2           0.249922         0.401487   0.219973           0  \n",
       "3           0.467200         0.658678   0.242428           0  \n",
       "4           0.409721         0.469762   0.585049           0  \n",
       "...              ...              ...        ...         ...  \n",
       "2006        0.310364         0.402799   0.627156           1  \n",
       "2007        0.565061         0.175889   0.395061           1  \n",
       "2008        0.563265         0.285745   0.578674           1  \n",
       "2009        0.397780         0.449156   0.440004           1  \n",
       "2010        0.471422         0.503458   0.591867           1  \n",
       "\n",
       "[2011 rows x 10 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Solids</th>\n",
       "      <th>Chloramines</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Organic_carbon</th>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.587349</td>\n",
       "      <td>0.577747</td>\n",
       "      <td>0.386298</td>\n",
       "      <td>0.568199</td>\n",
       "      <td>0.647347</td>\n",
       "      <td>0.292985</td>\n",
       "      <td>0.654522</td>\n",
       "      <td>0.795029</td>\n",
       "      <td>0.630115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.643654</td>\n",
       "      <td>0.441300</td>\n",
       "      <td>0.314381</td>\n",
       "      <td>0.439304</td>\n",
       "      <td>0.514545</td>\n",
       "      <td>0.356685</td>\n",
       "      <td>0.377248</td>\n",
       "      <td>0.202914</td>\n",
       "      <td>0.520358</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.388934</td>\n",
       "      <td>0.470876</td>\n",
       "      <td>0.506122</td>\n",
       "      <td>0.524364</td>\n",
       "      <td>0.561537</td>\n",
       "      <td>0.142913</td>\n",
       "      <td>0.249922</td>\n",
       "      <td>0.401487</td>\n",
       "      <td>0.219973</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.725820</td>\n",
       "      <td>0.715942</td>\n",
       "      <td>0.506141</td>\n",
       "      <td>0.521683</td>\n",
       "      <td>0.751819</td>\n",
       "      <td>0.148683</td>\n",
       "      <td>0.467200</td>\n",
       "      <td>0.658678</td>\n",
       "      <td>0.242428</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.610517</td>\n",
       "      <td>0.532588</td>\n",
       "      <td>0.237701</td>\n",
       "      <td>0.270288</td>\n",
       "      <td>0.495155</td>\n",
       "      <td>0.494792</td>\n",
       "      <td>0.409721</td>\n",
       "      <td>0.469762</td>\n",
       "      <td>0.585049</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>0.636224</td>\n",
       "      <td>0.580511</td>\n",
       "      <td>0.277748</td>\n",
       "      <td>0.418063</td>\n",
       "      <td>0.522486</td>\n",
       "      <td>0.342184</td>\n",
       "      <td>0.310364</td>\n",
       "      <td>0.402799</td>\n",
       "      <td>0.627156</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>0.470143</td>\n",
       "      <td>0.548826</td>\n",
       "      <td>0.301347</td>\n",
       "      <td>0.538273</td>\n",
       "      <td>0.498565</td>\n",
       "      <td>0.231359</td>\n",
       "      <td>0.565061</td>\n",
       "      <td>0.175889</td>\n",
       "      <td>0.395061</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>0.817826</td>\n",
       "      <td>0.087434</td>\n",
       "      <td>0.656389</td>\n",
       "      <td>0.670774</td>\n",
       "      <td>0.369089</td>\n",
       "      <td>0.431872</td>\n",
       "      <td>0.563265</td>\n",
       "      <td>0.285745</td>\n",
       "      <td>0.578674</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>0.424187</td>\n",
       "      <td>0.464092</td>\n",
       "      <td>0.459656</td>\n",
       "      <td>0.541633</td>\n",
       "      <td>0.615572</td>\n",
       "      <td>0.388360</td>\n",
       "      <td>0.397780</td>\n",
       "      <td>0.449156</td>\n",
       "      <td>0.440004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>0.322425</td>\n",
       "      <td>0.492891</td>\n",
       "      <td>0.841409</td>\n",
       "      <td>0.492136</td>\n",
       "      <td>0.656047</td>\n",
       "      <td>0.588709</td>\n",
       "      <td>0.471422</td>\n",
       "      <td>0.503458</td>\n",
       "      <td>0.591867</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2011 rows √ó 10 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ctiG4OLS83a7"
   },
   "source": [
    "## üß™ Experimentos no MLFLOW"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pA1lhima83bB",
    "ExecuteTime": {
     "end_time": "2024-11-15T16:41:21.610055Z",
     "start_time": "2024-11-15T16:41:21.598677Z"
    }
   },
   "source": [
    "models = {\n",
    "    \"TPOT AutoML\": [\n",
    "        {\"generations\": 3, \"population_size\": 20, \"verbosity\": 2},      # Para valida√ß√£o inicial r√°pida\n",
    "        {\"generations\": 5, \"population_size\": 50, \"verbosity\": 2},      # Configura√ß√£o equilibrada\n",
    "        {\"generations\": 7, \"population_size\": 75, \"verbosity\": 2},      # Configura√ß√£o robusta para dataset pequeno\n",
    "        {\"generations\": 10, \"population_size\": 100, \"verbosity\": 2},    # Explorando maior diversidade de pipelines\n",
    "        {\"generations\": 15, \"population_size\": 150, \"verbosity\": 2},    # Ideal para modelos mais complexos\n",
    "        {\"generations\": 20, \"population_size\": 200, \"verbosity\": 2},    # Configura√ß√£o avan√ßada\n",
    "        {\"generations\": 25, \"population_size\": 300, \"verbosity\": 2}     # Para m√°xima explora√ß√£o, dependendo do tempo\n",
    "    ],\n",
    "    \"Stacking Classifier\": [\n",
    "        # Combina√ß√µes simples e eficientes para valida√ß√£o r√°pida\n",
    "        {\n",
    "            \"estimators\": [\n",
    "                (\"rf\", RandomForestClassifier(n_estimators=50, max_depth=8, random_state=None)),\n",
    "                (\"gb\", GradientBoostingClassifier(n_estimators=30, learning_rate=0.1, max_depth=4, random_state=None)),\n",
    "                (\"dt\", DecisionTreeClassifier(max_depth=5, random_state=None)) \n",
    "            ],\n",
    "             \"final_estimator\": LogisticRegression(max_iter=500)\n",
    "        },\n",
    "        \n",
    "        # Combina√ß√µes intermedi√°rias com modelos robustos\n",
    "        {\n",
    "            \"estimators\": [\n",
    "                (\"rf\", RandomForestClassifier(n_estimators=100, max_depth=12, random_state=None)),\n",
    "                (\"cb\", CatBoostClassifier(iterations=50, learning_rate=0.1, depth=5, verbose=0, logging_level='Silent', allow_writing_files=False)),\n",
    "                (\"dt\", DecisionTreeClassifier(max_depth=7, random_state=None))  \n",
    "            ],\n",
    "             \"final_estimator\": LogisticRegression(max_iter=1000)\n",
    "        },\n",
    "        \n",
    "        # Explora√ß√£o avan√ßada com XGBoost e LightGBM\n",
    "        {\n",
    "            \"estimators\": [\n",
    "                (\"xgb\", XGBClassifier(n_estimators=75, learning_rate=0.1, max_depth=3, random_state=None)),\n",
    "                (\"lgbm\", LGBMClassifier(n_estimators=50, learning_rate=0.05, max_depth=4, random_state=None)),\n",
    "                (\"dt\", DecisionTreeClassifier(max_depth=6, random_state=None))  \n",
    "            ],\n",
    "             \"final_estimator\": LogisticRegression(max_iter=1000)\n",
    "        },\n",
    "        \n",
    "        # Combina√ß√µes avan√ßadas com mais estimadores\n",
    "        {\n",
    "            \"estimators\": [\n",
    "                (\"rf\", RandomForestClassifier(n_estimators=75, max_depth=10, random_state=None)),\n",
    "                (\"gb\", GradientBoostingClassifier(n_estimators=50, learning_rate=0.1, max_depth=3, random_state=None)),\n",
    "                (\"xgb\", XGBClassifier(n_estimators=50, learning_rate=0.05, max_depth=4, random_state=None)),\n",
    "                (\"dt\", DecisionTreeClassifier(max_depth=8, random_state=None))  \n",
    "            ],\n",
    "             \"final_estimator\": LogisticRegression(max_iter=1000)\n",
    "        },\n",
    "        \n",
    "        # Modelos focados em ensembles leves\n",
    "        {\n",
    "            \"estimators\": [\n",
    "                (\"xgb\", XGBClassifier(n_estimators=50, learning_rate=0.1, max_depth=4, random_state=None)),\n",
    "                (\"cb\", CatBoostClassifier(iterations=50, learning_rate=0.1, depth=6, verbose=0, logging_level='Silent', allow_writing_files=False)),\n",
    "                (\"dt\", DecisionTreeClassifier(max_depth=4, random_state=None)) \n",
    "            ],\n",
    "             \"final_estimator\": LogisticRegression(max_iter=1000)\n",
    "        },\n",
    "        \n",
    "        # Combina√ß√µes para maior diversidade\n",
    "        {\n",
    "            \"estimators\": [\n",
    "                (\"lgbm\", LGBMClassifier(n_estimators=75, learning_rate=0.05, max_depth=5, random_state=None)),\n",
    "                (\"cb\", CatBoostClassifier(iterations=50, learning_rate=0.1, depth=6, verbose=0, logging_level='Silent', allow_writing_files=False)),\n",
    "                (\"dt\", DecisionTreeClassifier(max_depth=6, random_state=None))  \n",
    "            ],\n",
    "             \"final_estimator\": LogisticRegression(max_iter=1000)\n",
    "        },\n",
    "        \n",
    "        # Ajuste final com modelos mais complexos e profundos\n",
    "        {\n",
    "            \"estimators\": [\n",
    "                (\"rf\", RandomForestClassifier(n_estimators=100, max_depth=15, random_state=None)),\n",
    "                (\"gb\", GradientBoostingClassifier(n_estimators=75, learning_rate=0.1, max_depth=5, random_state=None)),\n",
    "                (\"dt\", DecisionTreeClassifier(max_depth=10, random_state=None))  \n",
    "            ],\n",
    "             \"final_estimator\": LogisticRegression(max_iter=1000)\n",
    "        }\n",
    "    ]\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Preparar o ambiente do MLFlow e iniciar o experimento\n",
    "\n",
    "# Configurar o caminho relativo para os artefatos\n",
    "mlflow.set_tracking_uri(\"file:./mlruns\")\n",
    "\n",
    "# lista para armazenar os resultados\n",
    "results = []\n",
    "\n",
    "# Iniciar o experimento\n",
    "mlflow.set_experiment(\"exp_projeto_ciclo_3\")\n",
    "\n",
    "# Run para registrar modelos gerados pelo TPOTClassifier\n",
    "with mlflow.start_run(run_name=\"Modelos TPOT Treinados\") as main_run:  # Principal\n",
    "    counter = 0  # Contador para os experimentos\n",
    "    for params in models[\"TPOT AutoML\"]:  # Itera sobre os par√¢metros do TPOT AutoML\n",
    "        counter += 1\n",
    "        with mlflow.start_run(run_name=f\"{counter}. TPOTClassifier\", nested=True):  # Aninhada\n",
    "            # Instanciar e treinar o TPOTClassifier\n",
    "            model = TPOTClassifier(**params)\n",
    "            model.fit(x_train, y_train)\n",
    "\n",
    "            # Obter o pipeline otimizado\n",
    "            best_pipeline = model.fitted_pipeline_\n",
    "\n",
    "            # Avaliar as m√©tricas usando cross_val_score para o pipeline otimizado\n",
    "            accuracy = cross_val_score(best_pipeline, x_train, y_train, cv=10, scoring='accuracy').mean()\n",
    "            precision = cross_val_score(best_pipeline, x_train, y_train, cv=10, scoring='precision_weighted').mean()\n",
    "            recall = cross_val_score(best_pipeline, x_train, y_train, cv=10, scoring='recall_weighted').mean()\n",
    "            f1 = cross_val_score(best_pipeline, x_train, y_train, cv=10, scoring='f1_weighted').mean()\n",
    "\n",
    "            # Registrar os par√¢metros, m√©tricas e o pipeline otimizado\n",
    "            for key, value in params.items():\n",
    "                mlflow.log_param(key, str(value))\n",
    "            mlflow.log_metric(\"Accuracy\", accuracy)\n",
    "            mlflow.log_metric(\"Precision\", precision)\n",
    "            mlflow.log_metric(\"Recall\", recall)\n",
    "            mlflow.log_metric(\"F1 Score\", f1)\n",
    "            mlflow.sklearn.log_model(best_pipeline, artifact_path=\"TPOT_Best_Pipeline\",\n",
    "                                                    registered_model_name=\"TPOT_Best_Pipeline\", \n",
    "                                                    input_example=x_test.head(1))\n",
    "\n",
    "            # Armazenar resultados\n",
    "            results.append({\n",
    "                \"model\": \"TPOTClassifier\",\n",
    "                \"params\": params,\n",
    "                \"Accuracy\": accuracy,\n",
    "                \"Precision\": precision,\n",
    "                \"Recall\": recall,\n",
    "                \"F1 Score\": f1,\n",
    "            })\n",
    "\n",
    "# Run para registrar modelos gerados pelo StackingClassifier\n",
    "with mlflow.start_run(run_name=\"Modelos Stacking Treinados\") as main_run:  # Principal\n",
    "    counter = 0  # Contador para os experimentos\n",
    "    for params in models[\"Stacking Classifier\"]:  # Itera sobre os par√¢metros do Stacking Classifier\n",
    "        counter += 1\n",
    "        with mlflow.start_run(run_name=f\"{counter}. StackingClassifier\", nested=True):  # Aninhada\n",
    "            # Instanciar e treinar o StackingClassifier\n",
    "            model = StackingClassifier(**params)\n",
    "            model.fit(x_train, y_train)\n",
    "\n",
    "            # Avaliar as m√©tricas usando cross_val_score para o modelo\n",
    "            accuracy = cross_val_score(model, x_train, y_train, cv=10, scoring='accuracy').mean()\n",
    "            precision = cross_val_score(model, x_train, y_train, cv=10, scoring='precision_weighted').mean()\n",
    "            recall = cross_val_score(model, x_train, y_train, cv=10, scoring='recall_weighted').mean()\n",
    "            f1 = cross_val_score(model, x_train, y_train, cv=10, scoring='f1_weighted').mean()\n",
    "\n",
    "            # Registrar os par√¢metros, m√©tricas e o modelo treinado\n",
    "            for key, value in params.items():\n",
    "                mlflow.log_param(key, str(value))\n",
    "            mlflow.log_metric(\"Accuracy\", accuracy)\n",
    "            mlflow.log_metric(\"Precision\", precision)\n",
    "            mlflow.log_metric(\"Recall\", recall)\n",
    "            mlflow.log_metric(\"F1 Score\", f1)\n",
    "            mlflow.sklearn.log_model(model, artifact_path=\"Stacking_Classifier\",\n",
    "                                            registered_model_name=\"Stacking_Classifier\", \n",
    "                                            input_example=x_test.head(1))\n",
    "\n",
    "            # Armazenar resultados\n",
    "            results.append({\n",
    "                \"model\": \"StackingClassifier\",\n",
    "                \"params\": params,\n",
    "                \"Accuracy\": accuracy,\n",
    "                \"Precision\": precision,\n",
    "                \"Recall\": recall,\n",
    "                \"F1 Score\": f1,\n",
    "            })\n",
    "\n",
    "# Selecionar os 3 melhores modelos com base na m√©trica Accuracy\n",
    "best_models = sorted(results, key=lambda x: x[\"Accuracy\"], reverse=True)[:3]\n",
    "\n",
    "print(\"\\nMelhores Modelos:\\n\")\n",
    "for model_info in best_models:\n",
    "    print(model_info)\n",
    "print(\"\\n\\n\")\n",
    "\n"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ü¶æ Armazenando Melhor Modelo Com Pipeline "
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T23:20:35.742841Z",
     "start_time": "2024-11-15T23:20:31.734527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# Configurar o tracking URI relativo para MLFlow\n",
    "mlflow.set_tracking_uri(\"file:./mlruns\")\n",
    "\n",
    "# Nome do experimento\n",
    "experiment_name = \"exp_projeto_ciclo_3\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# Carregar o dataset\n",
    "data = pd.read_csv(\"water_potability.csv\").dropna()\n",
    "\n",
    "# Dividir o dataset em treino e teste\n",
    "x = data.drop(\"Potability\", axis=1)\n",
    "y = data[\"Potability\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=None)\n",
    "\n",
    "# Fun√ß√£o para criar e salvar o pipeline completo no MLFlow\n",
    "def save_pipeline(ml_model, model_name):\n",
    "    \"\"\"\n",
    "    Combina o modelo com um pipeline de pr√©-processamento e salva no MLFlow.\n",
    "    \"\"\"\n",
    "    # Combinar pipeline de pr√©-processamento com o modelo carregado\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', MinMaxScaler()),  # Normaliza√ß√£o dos dados\n",
    "        ('model', ml_model)\n",
    "    ])\n",
    "    pipeline.fit(x_train, y_train)\n",
    "\n",
    "    # Classe para encapsular o pipeline no MLFlow\n",
    "    class PipelineWrapper(mlflow.pyfunc.PythonModel):\n",
    "        def load_context(self, context):\n",
    "            self.pipeline = pipeline\n",
    "        \n",
    "        def predict(self, context, model_input):\n",
    "            return self.pipeline.predict(model_input)\n",
    "\n",
    "    # Salvar o pipeline completo no MLFlow\n",
    "    save_path = \"best_model\"\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    mlflow.pyfunc.save_model(path=save_path, python_model=PipelineWrapper())\n",
    "    print(f\"\\n{model_name} salvo em: {save_path}\")\n",
    "\n",
    "# Obter todos os runs do experimento, ordenando pelo Accuracy em ordem decrescente\n",
    "runs = mlflow.search_runs(experiment_names=[experiment_name], order_by=[\"metrics.`Accuracy` DESC\"], max_results=1)\n",
    "\n",
    "if not runs.empty:\n",
    "    # Selecionar o melhor run\n",
    "    best_run = runs.iloc[0]\n",
    "    best_run_id = best_run[\"run_id\"]\n",
    "    \n",
    "    # Verificar se h√° hist√≥rico de modelo registrado\n",
    "    if \"tags.mlflow.log-model.history\" in best_run:\n",
    "        log_model_history = json.loads(best_run[\"tags.mlflow.log-model.history\"])\n",
    "        artifact_path = log_model_history[0][\"artifact_path\"]\n",
    "\n",
    "        # Carregar o modelo usando o URI relativo\n",
    "        model_uri = f\"runs:/{best_run_id}/{artifact_path}\"\n",
    "        loaded_model = mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "        # Determinar o tipo do modelo e trat√°-lo\n",
    "        if isinstance(loaded_model, TPOTClassifier):\n",
    "            print(\"\\nModelo do TPOT AutoML carregado, combinando com o pr√©-processamento...\")\n",
    "            save_pipeline(loaded_model.fitted_pipeline_, \"Pipeline do TPOT AutoML\")\n",
    "        else:\n",
    "            print(\"\\nModelo do Stacking Classifier carregado, combinando com o pr√©-processamento...\")\n",
    "            save_pipeline(loaded_model, \"Pipeline do Stacking Classifier\")\n",
    "    else:\n",
    "        print(\"\\nNenhum hist√≥rico de modelo registrado encontrado para este run.\")\n",
    "else:\n",
    "    print(\"\\nNenhum run encontrado para o experimento especificado.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo do Stacking Classifier carregado, combinando com o pr√©-processamento...\n",
      "\n",
      "Pipeline do Stacking Classifier salvo em: best_model\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Modelos Registrados no MLFLOW"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T23:30:44.327151Z",
     "start_time": "2024-11-15T23:30:44.318798Z"
    }
   },
   "source": [
    "import subprocess\n",
    "\n",
    "# Definir o tracking URI do MLflow\n",
    "mlflow_tracking_uri = 'file:./mlruns'  # Caminho relativo\n",
    "\n",
    "mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "\n",
    "# Iniciar o MLflow UI em um subprocesso separado\n",
    "mlflow_process = subprocess.Popen([\"mlflow\", \"ui\", \"--host\", \"127.0.0.1\", \"--port\", \"5000\"])\n",
    "\n",
    "# Exibir a URL do MLflow UI\n",
    "print(\"MLflow UI est√° rodando em http://127.0.0.1:5000\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow UI est√° rodando em http://127.0.0.1:5000\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-15T23:20:35.895989Z",
     "start_time": "2024-11-15T23:20:35.891085Z"
    }
   },
   "source": [
    "# Parar o subprocesso do MLflow UI\n",
    "mlflow_process.terminate()\n",
    "\n",
    "# Confirmar que o MLflow UI foi parado\n",
    "print(\"MLflow UI foi parado\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow UI foi parado\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
